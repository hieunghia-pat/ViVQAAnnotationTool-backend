## Guideline for annotating OpenViVQA dataset

### Image collection
We used Google searching engine to collect images with different searching keywords involving numerous fields such as going shopping, parking, modern cities, ancient cities, ...

Currently, we collected 13,300 images and divided them into 133 subsets, each subset includes 100 images.

### Requirements
1. Each annotator is required to annotate <b>1</b> pair of question and answer (QA) for each image.
2. Limit the usage of word level in answer as it's not fluent and native when response to question in communication.
3. Use your own vocabulary.
4. Ask questions relating to any objects, activities or anything you see in images and answer with your knowledge.